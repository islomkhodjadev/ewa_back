version: "3.9"

services:
  backend:
    container_name: ewa_backend_django
    build: .
    ports:
      - "8000-8002:8000"   # Multiple ports for load balancing
    environment:
      DEBUG: ${DEBUG}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_HOST: db
      BOT_TOKEN: ${BOT_TOKEN}
      BOT_HOST: ${BOT_HOST}
      ALLOWED_HOSTS: ${ALLOWED_HOSTS}
      REDIS_HOST: redis
      REDIS_PORT: 6379
    depends_on:
      - db
      - redis
    deploy:
      replicas: 3              # Multiple backend instances
      resources:
        limits:
          memory: 1G           # Lightweight - no model loaded
          cpus: "0.7"
    command:
      - sh
      - -lc
      - >
        python manage.py collectstatic --noinput &&
        python manage.py migrate &&
        exec gunicorn core.asgi:application
        -k uvicorn.workers.UvicornWorker
        --bind 0.0.0.0:8000
        --workers 2
        --threads 2
        --timeout 120

    volumes:
      - ./static:/app/static
      - ./media:/app/media
      - ./logs:/app/log
      - .:/app

  db:
    image: pgvector/pgvector:pg17
    container_name: ewa_db_postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_MAX_CONNECTIONS: 200    # Increased connections
    volumes:
      - db_data:/var/lib/postgresql/data
    deploy:
      resources:
        limits:
          memory: 4G           # More memory for vector operations
          cpus: "2.0"

  redis:
    image: redis:7-alpine
    container_name: ewa_redis
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru --save ""
    volumes:
      - redis_data:/data
    deploy:
      resources:
        limits:
          memory: 2G           # More Redis memory for queues
          cpus: "0.5"

  # Fast workers for E5 embeddings - optimized for 8 cores
  worker-fast:
    build: .
    command: >
      celery -A core worker
      --loglevel=INFO
      --queues=fast,default
      --concurrency=6           # Higher concurrency per worker
      --prefetch-multiplier=1
      --max-tasks-per-child=200
      --autoscale=8,4          # Optimized autoscale
    environment:
      - CELERY_WORKER=true
      - CELERYD_CONCURRENCY=6
      - OMP_NUM_THREADS=1      # Optimize for multiple workers
    env_file: .env
    depends_on: [redis]
    volumes:
      - .:/app
    deploy:
      replicas: 4              # More worker instances
      resources:
        limits:
          memory: 2.5G         # For E5 model + overhead
          cpus: "1.2"

  beat:
    build: .
    command: celery -A core beat --loglevel=INFO
    env_file: .env
    depends_on: [redis]
    volumes:
      - .:/app
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.2"

  flower:
    build: .
    command: celery -A core flower --loglevel=INFO --port=5555
    env_file: .env
    depends_on: [redis]
    volumes:
      - .:/app
    ports:
      - "5555:5555"
    deploy:
      resources:
        limits:
          memory: 256M
          cpus: "0.2"

volumes:
  db_data:
  redis_data: